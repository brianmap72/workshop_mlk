{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, a file operation takes place in the following order.\n",
    "- Open a file\n",
    "- Read or write (perform operation)\n",
    "- Close the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to open a file?\n",
    "Python has a built-in function open() to open a file. This function **returns a file object**, also called a handle, as it is used to read or modify the file accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.txt\")    # open file in current directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the mode while opening a file. In mode, we specify whether we want to read 'r', write 'w' or append 'a' to the file. We also specify if we want to open the file in text mode or binary mode.\n",
    "\n",
    "The default is reading in text mode. In this mode, we get strings when reading from the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"test.txt\")      # equivalent to 'r' or 'rt'\n",
    "f = open(\"test_w.txt\",'w')  # write in text mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike other languages, the character 'a' does not imply the number 97 until it is encoded using ASCII (or other equivalent encodings). <br>\n",
    "\n",
    "Moreover, the default encoding is platform dependent. In windows, it is 'cp1252' but 'utf-8' in Linux.  <br>\n",
    "So, we must not also rely on the default encoding or else our code will behave differently in different platforms.  <br>\n",
    "\n",
    "Hence, when working with files in text mode, it is highly recommended to specify the encoding type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.txt\",mode = 'r',encoding = 'utf-8')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to close a file Using Python?\n",
    "When we are done with operations to the file, we need to properly close the file.\n",
    "Closing a file will free up the resources that were tied with the file and is done using Python close() method.\n",
    "Python has a garbage collector to clean up unreferenced objects but, we must not rely on it to close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"test.txt\",encoding = 'utf-8')\n",
    "# perform file operations\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is not entirely safe. If an exception occurs when we are performing some operation with the file, the code exits without closing the file.\n",
    "A safer way is to use a try...finally block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = open(\"test.txt\",encoding = 'utf-8')\n",
    "    # perform file operations\n",
    "finally:\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we are guaranteed that the file is properly closed even if an exception is raised, causing program flow to stop.\n",
    "The best way to do this is using the with statement. **This ensures that the file is closed when the block inside with is exited.**\n",
    "We don't need to explicitly call the close() method. It is done internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my first file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"test.txt\",encoding = 'utf-8') as f:\n",
    "    line = f.readline()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to write to File Using Python?\n",
    "In order to write into a file in Python, we need to open it in write 'w', append 'a' or exclusive creation 'x' mode.\n",
    "We need to be careful with the 'w' mode as it will overwrite into the file if it already exists. All previous data are erased.\n",
    "Writing a string or sequence of bytes (for binary files) is done using write() method. This method returns the number of characters written to the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test1.txt\",'w',encoding = 'utf-8') as f:\n",
    "    f.write(\"my first file\\n\")\n",
    "    f.write(\"This file\\n\\n\")\n",
    "    f.write(\"contains three lines\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to read files in Python?\n",
    "To read a file in Python, we must open the file in reading mode.\n",
    "There are various methods available for this purpose. We can use the read(size) method to read in size number of data. If size parameter is not specified, it reads and returns up to the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my f'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"test1.txt\",'r',encoding = 'utf-8')\n",
    "f.read(4)    # read the first 4 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'irst'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read(4)    # read the next 4 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' file\\nThis file\\n\\ncontains three lines\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read()     # read in the rest till end of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read()  # further reading returns empty sting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, the read() method returns newline as '\\n'. Once the end of file is reached, we get empty string on further reading.\n",
    "\n",
    "**We can change our current file cursor (position) using the seek() method. Similarly, the tell() method returns our current position (in number of bytes).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "my first file\n",
      "This file\n",
      "\n",
      "contains three lines\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"test1.txt\",'r',encoding = 'utf-8')\n",
    "print(f.tell())    # get the current file position\n",
    "f.seek(0)   # bring file cursor to initial position\n",
    "print(f.read())  # read the entire file\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read a file line-by-line using a for loop. This is both efficient and fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my first file\n",
      "This file\n",
      "\n",
      "contains three lines\n"
     ]
    }
   ],
   "source": [
    "f = open(\"test1.txt\",'r',encoding = 'utf-8')\n",
    "for line in f:\n",
    "    print(line, end = '')\n",
    "f.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines in file itself has a newline character '\\n'.\n",
    "Moreover, the print() end parameter to avoid two newlines when printing.\n",
    "Alternately, we can use readline() method to read individual lines of a file. This method reads a file till the newline, including the newline character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my first file\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"test1.txt\",'r',encoding = 'utf-8')\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This file\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contains three lines\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV Files With csv\n",
    "Reading from a CSV file is done using the reader object. The CSV file is opened as a text file with Python’s built-in open() function, which returns a file object. This is then passed to the reader, which does the heavy lifting.\n",
    "\n",
    "Here’s the employee_birthday.txt file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are name, department, birthday month\n",
      "\tJohn Smith works in the Accounting department, and was born in November.\n",
      "\tErica Meyers works in the IT department, and was born in March.\n",
      "Processed 3 lines.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('employee_birthday.txt') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            print(f'\\t{row[0]} works in the {row[1]} department, and was born in {row[2]}.')\n",
    "            line_count += 1\n",
    "    print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each row returned by the reader is a list of String elements containing the data found by removing the delimiters.** The first row returned contains the column names, which is handled in a special way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing CSV Files With csv\n",
    "You can also write to a CSV file using a writer object and the .write_row() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('employee_file.csv', mode='w') as employee_file:\n",
    "    employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    employee_writer.writerow(['John Smith', 'Accounting', 'November'])\n",
    "    employee_writer.writerow(['Erica Meyers', 'IT', 'March'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing CSV Files With the pandas Library\n",
    "\n",
    "**Of course, the Python CSV library isn’t the only game in town. Reading CSV files is possible in pandas as well. It is highly recommended if you have a lot of data to analyze.**\n",
    "\n",
    "pandas is an open-source Python library that provides high performance data analysis tools and easy to use data structures. pandas is available for all Python installations, but it is a key part of the Anaconda distribution and works extremely well in Jupyter notebooks to share data, code, analysis results, visualizations, and narrative text.\n",
    "\n",
    "Installing pandas and its dependencies in Anaconda is easily done:\n",
    "\n",
    "```$ conda install pandas```\n",
    "\n",
    "As is using pip/pipenv for other Python installations:\n",
    "\n",
    "```$ pip install pandas```\n",
    "\n",
    "We won’t delve into the specifics of how pandas works or how to use it. For an in-depth treatment on using pandas to read and analyze large data sets, check out Shantnu Tiwari’s superb article on working with large Excel files in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Name Hire Date   Salary  Sick Days remaining\n",
      "0  Graham Chapman  03/15/14  50000.0                   10\n",
      "1     John Cleese  06/01/15  65000.0                    8\n",
      "2       Eric Idle  05/12/14  45000.0                   10\n",
      "3     Terry Jones  11/01/13  70000.0                    3\n",
      "4   Terry Gilliam  08/12/14  48000.0                    7\n",
      "5   Michael Palin  05/23/13  66000.0                    8\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('hrdata.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['Hire Date'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Hire Date   Salary  Sick Days remaining\n",
      "Name                                                  \n",
      "Graham Chapman  03/15/14  50000.0                   10\n",
      "John Cleese     06/01/15  65000.0                    8\n",
      "Eric Idle       05/12/14  45000.0                   10\n",
      "Terry Jones     11/01/13  70000.0                    3\n",
      "Terry Gilliam   08/12/14  48000.0                    7\n",
      "Michael Palin   05/23/13  66000.0                    8\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('hrdata.csv', index_col='Name')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let’s fix the data type of the Hire Date field. You can force pandas to read data as a date **with the parse_dates optional parameter**, which is defined as a list of column names to treat as dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Hire Date   Salary  Sick Days remaining\n",
      "Name                                                   \n",
      "Graham Chapman 2014-03-15  50000.0                   10\n",
      "John Cleese    2015-06-01  65000.0                    8\n",
      "Eric Idle      2014-05-12  45000.0                   10\n",
      "Terry Jones    2013-11-01  70000.0                    3\n",
      "Terry Gilliam  2014-08-12  48000.0                    7\n",
      "Michael Palin  2013-05-23  66000.0                    8\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('hrdata.csv', index_col='Name', parse_dates=['Hire Date'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['Hire Date'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your CSV files doesn’t have column names in the first line, you can use the **names optional parameter** to provide a list of column names. You can also use this if you want to override the column names provided in the first line. In this case, you must also tell pandas.read_csv() to ignore existing column names using the header=0 optional parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Hired   Salary  Sick Days\n",
      "Employee                                     \n",
      "Graham Chapman 2014-03-15  50000.0         10\n",
      "John Cleese    2015-06-01  65000.0          8\n",
      "Eric Idle      2014-05-12  45000.0         10\n",
      "Terry Jones    2013-11-01  70000.0          3\n",
      "Terry Gilliam  2014-08-12  48000.0          7\n",
      "Michael Palin  2013-05-23  66000.0          8\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('hrdata.csv', \n",
    "            index_col='Employee', \n",
    "            parse_dates=['Hired'], \n",
    "            header=0, \n",
    "            names=['Employee', 'Hired','Salary', 'Sick Days'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing CSV Files With pandas\n",
    "Of course, if you can’t get your data out of pandas again, it doesn’t do you much good. Writing a DataFrame to a CSV file is just as easy as reading one in. Let’s write the data with the new column names to a new CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('hrdata.csv', \n",
    "            index_col='Employee', \n",
    "            parse_dates=['Hired'],\n",
    "            header=0, \n",
    "            names=['Employee', 'Hired', 'Salary', 'Sick Days'])\n",
    "df.to_csv('hrdata_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
